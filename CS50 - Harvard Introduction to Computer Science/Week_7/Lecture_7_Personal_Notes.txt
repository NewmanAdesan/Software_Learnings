
***
SQLite stores our data in a binary file, with 0s and 1s that represent data efficiently. 
We’ll interact with our tables of data through a command-line program, sqlite3.
***


***
There also isn’t a built-in way to undo commands, 
so if we make a mistake we might have to build our database again!
***









Data Collected:

	Last week, 
		- we collected a survey of Hogwarts house preferences, 
		- and tallied the data from a CSV file with Python.
		- CSV which is a flst-file database
		- which means that we can open it on nearly any operating system 
		- without special software like Microsoft Excel or Apple Numbers.


	This week, 
		- we’ll collect some more data about your favorite TV shows and their genres.
		- each person writes her favorite tv shows & picks what she thinks is the genre 

		- we get hundreds of responses from the audience, 
		- and start looking at them on Google Sheets, 
		- like we did last week, we can download our data as a CSV file 

		- from google sheets, our data will have three columns
		  "Timestamp", "title", "genres" 


	Notice that some rows have multiple genres, and those are surrounded by quotes, 
	for instance, "Crime, Drama", so that the commas within our data aren’t misinterpreted.



















Data Processing:

	Now we can use Python to process & querry this data, 
	writing lines of code for each query, utilizing libraries for reading the data like "csv"
	and utilizing techniques like regular expressions for finding patterns.



	Or we can use the tools a relational database gives us,
	which is relatively very short syntax to use, wherein those numerous lines of code
	we would have otherwise written are embeddedin the the syntax.



	Let's me show two example of querrying this data with python
	so you can have a sense of what i am talking about. 



















Data Processing ( with python ):
	

	Use a dictionary to count the entries for each title (case insensitive)
	and print items in the dictionary sorted based on the number of counts in reverse order.

		titles = {}

		with open("favorites.csv", "r") as file:
		    reader = csv.DictReader(file)

		    for row in reader:
		        title = row["title"].strip().upper()
		        if not title in titles:
		            titles[title] = 0
		        titles[title] += 1

		for title in sorted(titles, key=lambda title: titles[title], reverse=True):
		    print(title, titles[title])



	Do you see the amount of code we have to write, just for a singular querry		    
	Let's look at another Example	    



















Data Processing ( with python ):

	Let's count all the occurrences of a specific title.
	But, with this querry comes a problem we need to deal with.



	look at this entries "office", "the office", "theoffice", "thevoffice"
	all still references the show title called "the office".



	Using regular expression, we can solve this problem
	just as a reminder, in regular expressions here are some symbols used for matching
		. for any character
		.* for 0 or more characters
		.+ for 1 or more characters
		? for an optional character
		^ for start of input
		$ for end of input



	Python has a library for regular expressions called "re". it has a function, "search", 
	to which  we can pass a pattern and string to see if there is a mat

		import csv
		import re

		counter = 0

		with open("favorites.csv", "r") as file:
		    reader = csv.DictReader(file)

		    for row in reader:
		        title = row["title"].strip().upper()
		        if re.search("OFFICE", title):
		            counter += 1
		  
		print(f"Number of people who like The Office: {counter}")



















Relational databases

	Relational databases 
		- are programs that store data, ultimately in files, 
		- but with additional data structures and interfaces 
		- that allow us to search and store data more efficiently.



	When working with data, 
	we generally need four types of basic operations with the acronym CRUD:
		- CREATE
		- READ
		- UPDATE
		- DELETE



















SQL (intro):

	With another programming language, SQL (pronounced like “sequel”), 
	we can interact with databases with verbs like :
		CREATE, INSERT
		SELECT
		UPDATE
		DELETE, DROP



	Syntax in SQL might look like:	CREATE TABLE table (column type, ...);
	With this statement, we can create a table, which is like a spreadsheet with rows and columns.



	In SQL, we choose the types of data that each column will store.



















SQL (sqlite):

	We’ll use a common database program called SQLite, 


	SQLite stores our data in a binary file, 
	with 0s and 1s that represent data efficiently. 


	We’ll interact with our tables of data through a command-line program, sqlite3.
	We’ll run some commands in VS Code to import our CSV file into a database:

		$ sqlite3 
		SQLite version 3.36.0 2021-06-18 18:36:39
		Enter ".help" for usage hints.
		sqlite> .mode csv
		sqlite> .import favorites.csv favorites		
		sqlite> .schema
			CREATE TABLE IF NOT EXISTS "favorites"(
			  "Timestamp" TEXT,
			  "title" TEXT,
			  "genres" TEXT
			);


	.import
		- basically creates a table in our database with the data from our CSV file.
		- from the csv file, it creates a database file (.db).
		- it takes in two arguments, the csv filename 
		- and the name of the table you want to create


	.schema
		- this show the design of the table we just created
		- the syntax used for the table creation



















SQL (sqlite - reading data):

	We can select, or read data, with the general format
		SELECT column_name1, column_name2, ... FROM table_name


	SQL supports many functions that we can use to count and summarize data:
	such that, the data that is read or summarized can be processed to give a value
		AVG
		COUNT
		DISTINCT
		LOWER
		MAX
		MIN
		UPPER
		…


	We can clean up our titles as before, converting them to uppercase 
	and printing only the unique values: 
		sqlite> SELECT DISTINCT(UPPER(title)) FROM shows;
				... 
				| LAW AND ORDER                      |
				| B99                                |
				| GOT                                |
				...



	We can also get a count of how many responses there are:
		sqlite> SELECT COUNT(title) FROM favorites;
				+--------------+
				| COUNT(title) |
				+--------------+
				| 158          |
				+--------------+



















SQL (sqlite - filtering data ):

	We can also add more phrases to our command syntax:
		WHERE ( adding a Boolean expression to filter our data )
		LIKE  ( filtering responses more loosely )
		ORDER BY
		LIMIT
		GROUP BY
		…


	LIMIT
		- we can limit the number of results:
		- sqlite> SELECT title FROM favorites LIMIT 10;
				+-----------------------+
				|         title         |
				+-----------------------+
				| How i met your mother |
				| The Sopranos          |
				| Friday Night Lights   |
				| Family Guy            |
				| New Girl              |
				| Friends               |
				| Office                |
				| Breaking Bad          |
				| Modern Family         |
				| Office                |
				+-----------------------+


	WHERE			
		- we can also look for titles matching a string:
		- sqlite> SELECT title FROM favorites WHERE title LIKE "%office%";
				+-------------+
				|    title    |
				+-------------+
				| Office      |
				| Office      |
				| The Office  |
				| The Office  |
				| The Office  |
				| The Office  |
				| The Office  |
				| The Office  |
				| The Office  |
				| The Office  |
				| The Office  |
				| the office  |
				| The Office  |
				| ThE OffiCE  |
				| The Office  |
				| Thevoffice  |
				+-------------+
		- the % character is a placeholder for zero or more other characters, 
		- so SQL supports some pattern matching, 
		- though not it’s not as powerful as regular expressions are.
		- sqlite> SELECT title FROM favorites WHERE title = "%office%";



	WHERE, COUNT	
		- we can select just the count in our command:
		- sqlite> SELECT COUNT(title) FROM favorites WHERE title LIKE "%office%";
				+--------------+
				| COUNT(title) |
				+--------------+
				| 16           |
				+--------------+ 



















SQL (sqlite - editing data ):


	DELETE			
		- if we don’t like a show, we can even delete it:
		- sqlite> DELETE FROM favorites WHERE title LIKE "%friends%";
		- sqlite> SELECT COUNT(title) FROM favorites WHERE title LIKE "%friends%";
		- the count will return 0
		- With DELETE and DROP, we can remove rows and even entire tables as well. 


	UPDATE (single row)		
		- with SQL, we can change our data more easily and quickly than with Python.
		-	we can update a specific row/rows of data:
		- sqlite> SELECT title FROM favorites WHERE title = "Thevoffice";
		- sqlite> UPDATE favorites SET title = "The Office" WHERE title = "Thevoffice";
		- sqlite> SELECT title FROM favorites WHERE title = "Thevoffice";
		- sqlite> 
		- Now, we’ve changed that row’s value.



	UPDATE (multiple row)
		- there are several entries with a particular title, each has a different genre
		- our aim is to make the genre for a particular title uniform
			- sqlite> SELECT genres FROM favorites WHERE title = "Game of Thrones";
		- sqlite> UPDATE favorites SET genres = "Action, Adventure, Drama, Fantasy, Thriller, War" 
		          WHERE title = "Game of Thrones";
		- sqlite> SELECT genres FROM favorites WHERE title = "Game of Thrones";


	UNDO
		- there also isn’t a built-in way to undo commands, 
		- so if we make a mistake we might have to build our database again!



















SQL with Python :

	The need for combination
		- if we want to search for shows that are comedies, 
		- we have to search with not just 
		- SELECT title FROM favorites WHERE genre = "Comedy";, 
		- but also ... WHERE genre = "Comedy, Drama";, ... WHERE genre = "Comedy, News";, and so on.
		- we can use the LIKE keyword again, 
		- but two genres, “Music” and “Musical”, are similar enough for that to be problematic.
		- we can actually write our own Python program 
		- that will use SQL to import our CSV data into two tables:


	For example, from the favorites.csv, 
		- we can create two tables
		- a "shows" table, where we associate each show with an id and 
		- a "genres" table, where we have a show_id column that references our shows table, 
		- along with a genre column. Since each show may have more than one genre, 
		- we can have more than one row per show in our genres table, known as a one-to-many relationship. 
		- the data is now cleaner, since each genre name is in its own row. 	


	It turns out that SQL, too, has its own data types:
		- BLOB, for “binary large object”, raw binary data that might represent files
		- INTEGER
		- NUMERIC, number-like but not quite a number, like a date or time
		- REAL, for floating-point values
		- TEXT, like strings


	Columns can also have additional attributes:
		- PRIMARY KEY, like the id columns above that will be used to uniquely identify each row
		- FOREIGN KEY, like the show_id column above that refers to a column in some other table	



















SQL with Python (codebase):


# Imports titles and genres from CSV into a SQLite database
import cs50
import csv
  

# Create database
open("favorites8.db", "w").close()
db = cs50.SQL("sqlite:///favorites8.db")
  

# Create tables
db.execute("CREATE TABLE shows (id INTEGER, title TEXT NOT NULL, PRIMARY KEY(id))")
db.execute("CREATE TABLE genres (show_id INTEGER, genre TEXT NOT NULL, FOREIGN KEY(show_id) REFERENCES shows(id))")
  

# Open CSV file
with open("favorites.csv", "r") as file:
  
    # Create DictReader
    reader = csv.DictReader(file)
  
    # Iterate over CSV file
    for row in reader:
  
        # Canoncalize title
        title = row["title"].strip().upper()
  
        # Insert title
        show_id = db.execute("INSERT INTO shows (title) VALUES(?)", title)
  
        # Insert genres
        for genre in row["genres"].split(", "):

            db.execute("INSERT INTO genres (show_id, genre) VALUES(?, ?)", show_id, genre)		



















SQL with Python (dual table querry):

	With two tables, how to we now querry the database.
	Lets See some examples


	Example 1
		- we can select all the shows are that comedies 
		- by selecting from the genres table first, show_id's that are comedies, 
		- and then looking for those ids in the shows table:

		- SELECT title FROM shows WHERE id IN (SELECT show_id FROM genres WHERE genre = "Comedy");
		- SELECT DISTINCT(title) FROM shows WHERE id IN (SELECT show_id FROM genres WHERE genre = Comedy) ORDER BY title;


	Example 2
		- we can add new data to each table, 
		- for example, to add another show. 
		- first, we’ll add a new row to the shows table for "Seinfeld"
		- secondly, add the genre for Seinfeld as Comedy
		- lets also update the title "Seinfeld" to "SEINFELD" 	

		- INSERT INTO shows(title) VALUES("Seinfeld");
		- INSERT INTO genres(show_id, genre) VALUES(159, "Comedy");
		- UPDATE shows SET title = "SEINFELD" WHERE title = "Seinfeld"; 		



















SQL with Python (end note):

	We can write a program that asks the user for a show title and then prints its popularity



	when we querry the cs50.SQL() Object using the "execute function"
	the result of the querry is returned as a List structure, 
	whose entities is a dictionary representing each row



	# Create sqlite gateway
	db = cs50.SQL(sqlite:///favorites8.db)


	# Obtain user input
	user_title = input("Title: ").strip()


	# Querry Database
	rows = db.execute("SELECT COUNT(title) AS counter FROM shows WHERE title = ?", user_title)	


	# result has only one row - the count	
	row = rows[0]

	print(row["counter"])



















IMDB ( tables ):
	lets look at a database from IMDB called "shows.db"	
	first, look at all the schemas (tables) in the database

	CREATE TABLE shows (
                    id INTEGER,
                    title TEXT NOT NULL,
                    year NUMERIC,
                    episodes INTEGER,
                    PRIMARY KEY(id)
                );

	CREATE TABLE genres (
	                    show_id INTEGER NOT NULL,
	                    genre TEXT NOT NULL,
	                    FOREIGN KEY(show_id) REFERENCES shows(id)
	                );

	CREATE TABLE stars (
	                show_id INTEGER NOT NULL,
	                person_id INTEGER NOT NULL,
	                FOREIGN KEY(show_id) REFERENCES shows(id),
	                FOREIGN KEY(person_id) REFERENCES people(id)
	            );

	CREATE TABLE writers (
	                show_id INTEGER NOT NULL,
	                person_id INTEGER NOT NULL,
	                FOREIGN KEY(show_id) REFERENCES shows(id),
	                FOREIGN KEY(person_id) REFERENCES people(id)
	            );

	CREATE TABLE ratings (
	                show_id INTEGER NOT NULL,
	                rating REAL NOT NULL,
	                votes INTEGER NOT NULL,
	                FOREIGN KEY(show_id) REFERENCES shows(id)
	            );

	CREATE TABLE people (
	                id INTEGER,
	                name TEXT NOT NULL,
	                birth NUMERIC,
	                PRIMARY KEY(id)
	            );



















IMDB (creating index):

	We can get our querry lookup time
		sqlite> .timer on
		sqlite> SELECT * FROM shows WHERE title = "The Office" and year = "2005";
		...
		Run Time: real 0.021 user 0.016419 sys 0.004117



	In SQL, We can create an "index", or additional data structures 
	that our database program will use for future searches:	 
		sqlite> CREATE INDEX "title_index" ON "shows" ("title");
		Run Time: real 0.349 user 0.195206 sys 0.051217	

		sqlite> SELECT * FROM shows WHERE title = "The Office";
		...
		Run Time: real 0.000 user 0.000104 sys 0.000124



	B-TREES
		- notice how much faster out look up has become. 
		- it turns out that these data structures are generally B-trees, 
		- like binary trees but with more children, 
		- with nodes organized such that we can search faster than linearly	

		- creating an index takes some time up front, perhaps by sorting the data, 
		- but afterwards we can search much more quickly.


	The downside to having lots of indexes is that each of them take up some amount of space, 
	which might become significant with lots of data and lots of indexes	



















IMDB (multiple table querry):	

There are two basic ways we can do this,
	- nesting querries
	- using the JOIN keyword (joining tables)  


For example, we can get all the titles of shows starring a particular person:	


USING NESTED QUERRIES
	sqlite> SELECT title FROM shows WHERE id IN 
	    ..> ( SELECT show_id FROM stars WHERE person_id = 
		..> (SELECT id FROM people WHERE name = "Steve Carell") );


	sqlite> CREATE INDEX person_index ON stars (person_id);
	Run Time: real 0.890 user 0.662294 sys 0.097505
	sqlite> CREATE INDEX show_index ON stars (show_id);
	Run Time: real 0.644 user 0.469162 sys 0.058866
	sqlite> CREATE INDEX name_index ON people (name);
	Run Time: real 0.840 user 0.609600 sys 0.088177	



USING JOIN
	- it turns out that we can use JOIN commands to combine tables in our queries.
	- we can virtually combine tables based on their foreign keys, 
	- and use their columns as though they were one table

	sqlite> SELECT title FROM 
	    ..> people JOIN stars 
	    ..> ON people.id = stars.person_id
		..> JOIN shows 
		..> ON stars.show_id = shows.id
		..>	WHERE name = "Steve Carell";	


	OR

	sqlite> SELECT title FROM people, stars, shows
		..> WHERE people.id = stars.person_id
		..> AND	stars.show_id = shows.id
		..> AND name = "Steve Carell";	



















SQL Problems ( injection attack ):

	SQL injection attack, 
		- where someone can inject, or place, 
		- their own commands into inputs that we then run on our database.



	Let's look at an example of a login page for a website 
	that asks for a username and password, and checks for those in a SQL database. 
	we will show two ways of writing the SQL querry



	VERSION 1	
		rows = db.execute(f"SELECT * FROM users WHERE username = '{username}' AND password = '{password}'")
		if len(rows) == 1:
		    # Log user in



	VERSION 2 
		rows = db.execute("SELECT * FROM users WHERE username = ? AND password = ?", username, password)
		if len(rows) == 1:
		    # Log user in



	Looking at version 1 
		- user can be clever & try to comment out the rest of the querry that asks for password
		- for example, if a user types in malan@harvard'-- as ther input
		- then the query will end up being

		rows = db.execute(f"SELECT * FROM users WHERE username = 'malan@harvard.edu'--' AND password = '{password}'")

		- this query will actually select the row where username = 'malan@harvard.edu', 
		- without checking the password, since the single quotes end the input, 
		- and -- turns the rest of the line into a comment in SQL.

		- the user could even add a semicolon, ;, 
		- and write a new command of their own, that our database will execute.



	Looking at version 2
		- by using the ? symbols as placeholders, our SQL library will escape the input, 
		- or prevent dangerous characters from being interpreted as part of the command. 



















SQL Problems ( race conditions ):


Race conditions, 
	- where shared data is unintentionally changed by code 
	- running on different devices or servers at the same time.


One example is a popular post getting lots of likes. 
	- a server might try to increment the number of likes, 
	- asking the database for the current number of likes, 
	- adding one, and updating the value in the database:

	rows = db.execute("SELECT likes FROM posts WHERE id = ?", id);
	likes = rows[0]["likes"]
	db.execute("UPDATE posts SET likes = ? WHERE id = ?", likes + 1, id);


This is where the problem is
	- two different servers, responding to two different users, 
	- might get the same starting number of likes 
	- since the first line of code runs at the same time on each server.
	- then, both will use UPDATE to set the same new number of likes, 
	- even though there should have been two separate increments. 



















SQL Problems ( race conditions ):

	Another example might be of two roommates and a shared fridge in their dorm. 
		- the first roommate comes home, and sees that there is no milk in the fridge. 
		- so the first roommate leaves to the store to buy milk. 
		- while they are at the store, the second roommate comes home, 
		- sees that there is no milk, and leaves for another store to get milk as well. 

		- later, there will be two jugs of milk in the fridge.
		- we can solve this problem by locking the fridge 
		- so that our roommate can’t check whether there is milk until we’ve gotten back.



	To solve this problem, 
		- SQL supports transactions, 
		- where we can lock rows in a database, 
		- such that a particular set of actions are atomic, 
		- or guaranteed to happen together.



	For example, we can fix our problem above with:
		db.execute("BEGIN TRANSACTION")
		rows = db.execute("SELECT likes FROM posts WHERE id = ?", id);
		likes = rows[0]["likes"]
		db.execute("UPDATE posts SET likes = ? WHERE id = ?", likes + 1, id);
		db.execute("COMMIT")


		- the database will ensure that all the queries in between are executed together.
		- but the more transactions we have, the slower our applications might be, 
		- since each server has to wait for other servers’ transactions to finish.